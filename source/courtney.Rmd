---
title: "Scraping"
author: "Courtney Johnson"
date: "May 4, 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(httr)
library(rvest)
library(pdftools)
library(glue)
```


### Wyoming

```{r, scrape}
url = "https://health.wyo.gov/publichealth/infectious-disease-epidemiology-unit/disease/novel-coronavirus/covid-19-map-and-statistics/"

wy_xml = read_html(url) %>%
  html_nodes('center') %>%
  html_table(fill = TRUE, header = TRUE)
```


### New Hampshire

```{r, nh_scrape}
date = "04272020"

# put the date into url and create a way to automatically run things with different dates
url = "https://www.dhhs.nh.gov/dphs/cdcs/covid19/covid-weekly-report-{date}.pdf"
url = glue(url)

# read in text
nh_text = pdf_text(url) %>%
  readr::read_lines()

# preview text
# nh_text

# save text for first table
outcome_table = nh_text[4:7] %>%
  str_replace_all(",", "") %>%
  str_replace("Intensive Care Unit", "ICU") %>%
  str_squish() %>%
  strsplit(split = " ") 

# add recovered and deaths labels to the existing row with labels
outcome_table[[3]][8:9] = outcome_table[[2]][1:2]

# save values and column names
outcome_table = outcome_table[3:4]


# make dataframe and add variable names
outcomes = outcome_table[2] %>%
  plyr::ldply() %>%
  rename(outcome = V1, current_inf = V2, cumulative_inf = V3, current_hosp = V4,
         cumulative_hosp = V5, current_icu = V6, cumulative_icu = V7, 
         recovered = V8, deaths = V9)
  

# save text for first demographic table
demo1 = nh_text[9:25] %>%
  str_replace_all("% of Total", "Total_Perc") %>%
  str_replace("SUMMARY OF PERSONS WITH COVID-19", "Characteristic") %>%
  str_replace("Healthcare Workers", "Healthcare_workers") %>%
  str_replace("Age Group \\(in years\\)", "Age_grp") %>%
  str_replace_all(" - ", "_") %>%
  str_replace("-", "_") %>%
  str_replace(",", "") %>%
  str_replace(" \\+", "_") %>%
  str_squish() %>%
  strsplit(split = " ")

# combine variable names
demo1[[2]][2:7] = demo1[[3]][1:6]

# save values and create data frames
# sex
sex_demo = demo1[6:7] %>%
  plyr::ldply() %>%
  rename(sex = V1, num_infections = V2, percent_of_total_inf = V3,
         num_hosp = V4, percent_of_total_hosp = V5, num_deaths = V6, 
         percent_of_total_deaths = V7) %>%
  mutate(sex = if_else(sex == "Male", "male", "female"))

# age group
age_demo = demo1[9:17] %>%
  plyr::ldply() %>%
  rename(age_grp = V1, num_infections = V2, percent_of_total_inf = V3,
         num_hosp = V4, percent_of_total_hosp = V5, num_deaths = V6, 
         percent_of_total_deaths = V7)

# healthcare workers
healthcare_demo = demo1[4] %>%
  plyr::ldply() %>%
  rename(characteristic = V1, num_infections = V2, percent_of_total_inf = V3,
         num_hosp = V4, percent_of_total_hosp = V5, num_deaths = V6, 
         percent_of_total_deaths = V7) 

 
# save text for second demographic table (race/eth)
demo2 = nh_text[36:45] %>%
  str_replace_all("% of Total", "Total_Perc") %>%
  str_replace("Race/Ethnicity", "Race_Eth") %>%
  str_replace("White2", "white") %>%
  str_replace("Hispanic/Latino1", "hispanic") %>%
  str_replace("Black or African American2", "black") %>%
  str_replace("Other3", "other") %>%
  str_replace("Asian2", "asian") %>%
  str_replace("Total Persons with", "Tot_info") %>%
  str_replace("Percent of NH", "Perc_NH") %>%
  str_replace(",", "") %>%
  str_squish() %>%
  strsplit(split = " ")

# keep values
race_eth_demo = demo2[4:8] %>%
  plyr::ldply() %>%
  rename(race_eth = V1, num_inf = V2, percent_of_total_inf = V3, num_hosp = V4,
         percent_of_total_hosp = V5, num_deaths = V6, 
         percent_of_total_deaths = V7, percent_of_NH_pop = V8) 

# modify race/eth to show total with collected info
race_eth_demo = race_eth_demo %>%
  mutate(percent_of_total_inf = paste(percent_of_total_inf, "/1525"),
         percent_of_total_hosp = paste(percent_of_total_hosp, "/211"),
         percent_of_total_deaths = paste(percent_of_total_deaths, "/40"))
```

### Show New Hampshire tables
```{r}
knitr::kable(outcomes)

knitr::kable(sex_demo)

knitr::kable(age_demo)

knitr::kable(healthcare_demo)

knitr::kable(race_eth_demo)
```


### Kansas

```{r, kansas}
# must redownload pdf and change date 
ks_date = "05062020"

# to run without knitting, use single ., to run with knitting, use double ..
# issue with how i originally made the file?
location = "../pdfs/Kansas_Demo_{ks_date}.pdf"
location = glue(location)

ks_text = pdf_text(location) %>%
  readr::read_lines()

# ks_text

# replace necessary strings
ks_race = ks_text[21:27] %>%
  str_replace_all(",", "") %>%
  str_replace("Number of Cases", "num_cases") %>%
  str_replace("Rate per 100000", "rate_per_100000") %>%
  str_replace("Black or African American", "black") %>%
  str_replace("American Indian or Alaska Nat..", "american_indian_alaskan_native") %>%
  str_replace("White", "white") %>%
  str_replace("Asian", "asian") %>%
  str_replace("Other Race", "other") %>%
  str_replace("Not Reported/Missing", "not_reported") %>%
  str_squish() %>%
  strsplit(split = " ")

# add missing value to third column of last line
ks_race[[7]][3] = "na"

# make into data frame
ks_race_demo = ks_race[2:7] %>%
  plyr::ldply() %>%
  rename(race = V1, num_cases = V2, rate_per_100000 = V3)



# ethnicity demo
ks_eth = ks_text[30:33] %>%
  str_replace_all(",", "") %>%
  str_replace("Cases", "num_cases") %>%
  str_replace("100000", "rate_per_100000") %>%
  str_replace("Ethnicity", "eth") %>%
  str_replace("Not Hispanic/Latino", "non_hispanic") %>%
  str_replace("Hispanic/Latino", "hispanic") %>%
  str_replace("Unknown or Missing", "not_reported") %>%
  str_squish() %>%
  strsplit(split = " ")

# add missing to third column of non reported
ks_eth[[4]][3] = "na"

# make into data frame
ks_eth_demo = ks_eth[2:4] %>%
  plyr::ldply() %>%
  rename(ethnicity = V1, num_cases = V2, rate_per_100000 = V3)


# sex demo
ks_sex = ks_text[7:11] %>%
  str_replace_all(",", "") %>%
  str_replace("% of Cases", "percent_of_cases") %>%
  str_replace("Not Reported/Unknown", "not_reported") %>%
  str_replace("Male", "male") %>%
  str_replace("Female", "female") %>%
  str_squish() %>%
  strsplit(split = " ")

# cut out age group data
ks_sex[[1]] = ks_sex[[1]][1:3]
ks_sex[[2]] = ks_sex[[2]][1:3]
ks_sex[[3]] = ks_sex[[3]][1:3]
ks_sex[[4]] = ks_sex[[4]][1:3]
ks_sex[[5]] = ks_sex[[5]][1:3]

# make into data frame
ks_sex_demo = ks_sex[2:5] %>%
  plyr::ldply() %>%
  rename(sex = V1, num_cases = V2, percent_of_cases = V3)

# age group demo
ks_age = ks_text[7:19] %>%
  str_replace_all(",", "") %>%
  str_replace_all("years", "") %>%
  str_replace_all("Not Reported", "not_reported") %>%
  str_replace_all("Total", "total") %>%
  str_replace("Age Group", "age_grp") %>%
  str_replace_all("Cases", "num_cases") %>%
  str_replace("% of total", "percent_of_tot") %>%
  str_squish() %>%
  strsplit(split = " ")

# cut sex data out 
ks_age[[1]] = ks_age[[1]][6:8]
ks_age[[2]] = ks_age[[2]][4:6]
ks_age[[3]] = ks_age[[3]][4:6]
ks_age[[4]] = ks_age[[4]][4:6]
ks_age[[5]] = ks_age[[5]][4:6]

# make into data frame
ks_age_demo = ks_age[2:13] %>%
  plyr::ldply() %>%
  rename(age_grp = V1, num_cases = V2, percent_of_total = V3)
```

### Kansas Tables
```{r, ks_tables}
knitr::kable(ks_age_demo)

knitr::kable(ks_sex_demo)

knitr::kable(ks_race_demo)

knitr::kable(ks_eth_demo)
```


### Idaho
```{r, idaho}
# so far, it looks like the most difficult but accurate way is to download the crosstab data from the dashboard (sex, age, race, ethnicity, total) for both cases and deaths separately
# this would mean downloading 10 csv files each day manually-there isn't a file location link that I can find that would enable me to loop through automatically downloading each file


date = "05082020"

# age file is formatted differently
type = c("Eth", "Race", "Sex", "Total")

file_name = "../Data/ID_Case{type}_{date}.csv"

file_loc = glue(file_name)

df = map(.x = file_loc, ~read.csv(.x, header = TRUE, sep = "\t", 
                             fileEncoding = "UTF-16LE")) 


read.csv("../Data/ID_CaseAge_05082020.csv", header = FALSE, sep = "",
         fileEncoding = "UTF-16LE")
```

### South Dakota
```{r, sd}
url = "https://doh.sd.gov/news/coronavirus.aspx#SD"

sd_xml = read_html(url)

# this doesn't work, because it doesn't pick up the table on the dashboard
# tabs = sd_xml %>%
#   html_nodes('table') %>%
#   html_table(fill = TRUE, header = TRUE)
```

