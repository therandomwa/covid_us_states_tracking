---
title: "COVID State Web Scraping"
output: html_document
---

```{r, message = FALSE, warning = FALSE }
library(tidyverse)
library(pdftools)
library(rvest)
library(lubridate)

# Helper functions for data cleaning
skeleton_col = function() {
  # Need to make a named vector to make it easier to insert data
  # in a cel-wise fashion
  desired_cols = c(
    "Total",
    "Age: 0-19", "Age: 20-29", "Age: 30-39", "Age: 40-49",
    "Age: 50-59", "Age: 60-69", "Age: 70-79", "Age: 80+", 
    "Age: Unk.",
    "Sex: M", "Sex: F", "Sex: Unk",
    "Race: Hispanic", "Race: Non-Hispanic",
    "Ethnicity: White", 
    "Ethnicity: AfrA",
    "Ethnicity: NatA",
    "Ethnicity: Asian", 
    "Ethnicity: Other",
    "Ethnicity: Multi-race", 
    "Ethnicity: Unknown")
  skeleton = vector(mode = "list", length = length(desired_cols))
  names(skeleton) = desired_cols
  return(skeleton)
}

skeleton_table = function() {
  # Create a table of blanks using named vectors
  # Easy insert of data
  skeleton = list(
    "data" = names(skeleton_col()),
    "tested" = skeleton_col(),
    "positive" = skeleton_col(),
    "negative" = skeleton_col(),
    "recovered" = skeleton_col(),
    "death" = skeleton_col(),
    "hospitalized" = skeleton_col())
  return(skeleton)
}
```

# Nevada

- Doesn't work out because data is hidden under the Microsoft BI dashboard and the pdfs that hold the data show images, not text

```{r}
nevada = read_html("https://nvhealthresponse.nv.gov/") %>% 
    html_nodes(".js-side-cta") %>% 
    html_nodes(".split-content-section") %>% 
    html_nodes(".split-content-section__container") %>% 
    html_nodes(".content-intro") %>% 
    html_nodes("iframe") %>% 
    xml_attrs() %>% 
    .[[1]] %>% 
    .[1] %>% # This returns another html that comes from the iframe
    read_html() %>% 
    html_nodes("#pbiAppPlaceHolder")
  
  return(nevada)
```

# Iowa

```{r}
# Need to access the data through daily pdfs
# Get pdfs from Tableau download: https://coronavirus.iowa.gov/#CurrentStatus

# Pain point: must redownload pdf from Tableau table every day, 
# then put it in pdfs folder
# Download the "Current Status" and "Demographics" sheets as pdf 

now = Sys.time() %>% as_date() %>% as.character()
date_for_url = paste0(str_sub(now, 6,7), 
                      str_sub(now, 9, 10), 
                      str_sub(now, 1,4))

iowa = pdf_text(paste0("../pdfs/IowaCOVID19_", date_for_url, ".pdf"))

extract_iowa_data = function(pdf_data) {
  total_page = pdf_data[1] %>% str_split(., "\n") %>% .[[1]]
  demographics_page = pdf_data[2] %>% str_split(., "\n") %>% .[[1]]
  
  total_confirmed_cases = total_page[35] %>% 
    str_split(" ") %>% .[[1]] %>% head(1) %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  total_deaths = total_page[35] %>% 
    str_split(" ") %>% .[[1]] %>% tail(1) %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  total_people_tested = total_page[37] %>% 
    str_split(" ") %>% .[[1]] %>% head(1) %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  total_cases_recovered = total_page[37] %>% 
    str_split(" ") %>% .[[1]] %>% tail(1) %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  
  return(list(
    total_confirmed_cases = total_confirmed_cases,
    total_deaths = total_deaths,
    total_people_tested = total_people_tested,
    total_cases_recovered = total_cases_recovered
    demographic_string = demographic_page
  ))
}


extract_iowa_data(iowa)
```

# Delaware

```{r}
delaware = read_html("https://myhealthycommunity.dhss.delaware.gov/locations/state")
```

# Oklahoma

```{r}
extract_oklahoma_data = function() {
  data_url = "https://storage.googleapis.com/ok-covid-gcs-public-download/covid19_cases_summary.pdf"
  
  oklahoma = pdf_text(data_url) %>% 
    str_split(., "\n") %>% .[[1]] %>% 
    map(., str_squish)
  
  cases = oklahoma %>% .[[3]] %>% 
    str_split(., " ", simplify = TRUE) %>% 
    .[1, 5] %>% 
    str_replace(., ",", "") %>% as.numeric()
    
  deaths = oklahoma %>% .[[3]] %>% 
    str_split(., " ", simplify = TRUE) %>% 
    .[1, 6] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  recovered = oklahoma %>% .[[3]] %>% 
    str_split(., " ", simplify = TRUE) %>% 
    .[1, 7] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  # WARNING: super fragile coding follows
  # Makes some big assumptions on where numbers are placed
  # based on position, assumes these indices wont change much
  
  white_pct = oklahoma %>% .[[22]] %>% 
    str_split(., " ", simplify = TRUE) %>% .[1, 2] %>% 
    str_replace(., "%", "") %>% as.numeric() / 100
  
  unknown_race_pct = oklahoma %>% .[[25]] %>% 
    str_replace(., "%", "") %>% as.numeric()
  
  native_american_pct = oklahoma %>% .[[31]] %>% 
    str_split(., " ", simplify = TRUE) %>% .[1, 1] %>% 
    str_replace(., "%", "") %>% as.numeric() / 100

  multiple_race_pct = oklahoma %>% .[[42]] %>% 
    str_replace(., "%", "") %>% as.numeric() / 100
  
  asian_pct = oklahoma %>% .[[47]] %>% 
    str_replace(., "%", "") %>% as.numeric() / 100  
  
  african_american_pct = oklahoma %>% .[[38]] %>% 
    str_replace(., "%", "") %>% as.numeric() / 100
  
  between_0_and_4_pct = oklahoma %>% .[[39]] %>% 
    str_split(., " ", simplify = TRUE) %>% .[1, 2] %>% 
    str_replace(., "%", "") %>% as.numeric() / 100
  
  between_5_and_17_pct = oklahoma %>% .[[37]] %>% 
    str_split(., " ", simplify = TRUE) %>% .[1, 2] %>% 
    str_replace(., "%", "") %>% as.numeric() / 100  

  between_18_and_35_pct = oklahoma %>% .[[33]] %>% 
    str_split(., " ", simplify = TRUE) %>% .[1, 4] %>% 
    str_replace(., "%", "") %>% as.numeric() / 100
  
  between_36_and_49_pct = oklahoma %>% .[[35]] %>% 
    str_split(., " ", simplify = TRUE) %>% .[1, 2] %>% 
    str_replace(., "%", "") %>% as.numeric() / 100  

  between_50_and_64_pct = oklahoma %>% .[[32]] %>% 
    str_split(., " ", simplify = TRUE) %>% .[1, 2] %>% 
    str_replace(., "%", "") %>% as.numeric() / 100
  
  older_than_65_pct = oklahoma %>% .[[30]] %>% 
    str_split(., " ", simplify = TRUE) %>% .[1, 2] %>% 
    str_replace(., "%", "") %>% as.numeric() / 100   
   
  unknown_age_pct = oklahoma %>% .[[41]] %>% 
    str_split(., " ", simplify = TRUE) %>% .[1, 3] %>% 
    str_replace(., "%", "") %>% as.numeric() / 100
    
  return(list(
    cases = cases,
    deaths = deaths,
    recovered = recovered,
    white_cases = floor(cases * white_pct),
    unknown_race_cases = floor(cases * unknown_race_pct),
    african_american_cases = floor(cases * african_american_pct),
    native_american_cases = floor(cases * native_american_pct),
    multiple_race_cases = floor(cases * multiple_race_pct),
    asian_cases = floor(cases * asian_pct),
    african_american_cases = floor(cases * african_american_pct),
    between_0_and_4_cases = floor(cases * between_0_and_4_pct),
    between_5_and_17_cases = floor(cases * between_5_and_17_pct),
    between_18_and_35_cases = floor(cases * between_18_and_35_pct),
    between_36_and_49_cases = floor(cases * between_36_and_49_pct),
    between_50_and_64_cases = floor(cases * between_50_and_64_pct),
    older_than_65_cases = floor(cases * older_than_65_pct),
    unknown_age_cases = floor(cases * unknown_age_pct)
  ))
}

oklahoma = extract_oklahoma_data()
oklahoma
```

# Arizona

```{r}
extract_arizona_data = function() {
  url = "https://www.azdhs.gov/preparedness/epidemiology-disease-control/infectious-disease-epidemiology/covid-19/dashboards/index.php"
  # arizona = read_html()
  arizona = htmlParse(GET(url, user_agent("Mozilla")))
  return(arizona)
}

arizona = extract_arizona_data()
```

# Mississippi

```{r}
extract_mississippi_data = function() {
  
  # Extract pdf locations from the site to account for updates
  site_url = "https://msdh.ms.gov/msdhsite/_static/14,0,420.html"
  html = read_html(site_url) %>% 
    html_nodes("body") %>% 
    html_nodes("#pageContainer") %>% 
    html_nodes("#pageContent") %>% 
    html_nodes("#article") %>% 
    html_nodes(".msdh") %>% 
    html_nodes("ul") %>% .[[7]]
  
  cases_path = html %>% 
    xml_child(., 1) %>% 
    html_nodes("a") %>% 
    xml_attrs() %>% .[[1]]
  
  death_path = html %>% 
    xml_child(., 2) %>% 
    html_nodes("a") %>% 
    xml_attrs() %>% .[[1]]
  
  url = paste0("https://msdh.ms.gov/msdhsite/_static/", cases_path)
  deaths_url = paste0("https://msdh.ms.gov/msdhsite/_static/", death_path)
  
  
  
  # Table is by county, just need to look at the last row
  mississippi = pdf_text(url) %>% .[2] %>% 
    str_split(., "\n") %>% .[[1]] %>% .[17] %>% # Last row
    str_squish() %>%
    str_split(., " ") %>%  .[[1]] %>% .[-1] %>% # Removing "Total" string
    as.numeric()

  deaths = pdf_text(deaths_url) %>% .[2] %>% 
    str_split(., "\n") %>% .[[1]] %>% .[17] %>% # Last row
    str_squish() %>%
    str_split(., " ") %>%  .[[1]] %>% .[-1] %>% # Removing "Total" string
    as.numeric()
  
  return(list(
    cases = mississippi[1],
    deaths = deaths[1],
    white_cases = mississippi[3] + mississippi[9] + mississippi[15],
    unknown_race_cases = mississippi[7] + mississippi[13] + mississippi[19],
    native_american_cases = mississippi[4] + mississippi[10] + mississippi[16],
    african_american_cases = mississippi[2] + mississippi[8] + mississippi[14],
    asian_cases = mississippi[5] + mississippi[11] + mississippi[17],
    other_race_cases = mississippi[6] + mississippi[12] + mississippi[18],
    white_deaths = deaths[3] + deaths[9] + deaths[15],
    unknown_race_deaths = deaths[7] + deaths[13] + deaths[19],
    native_american_deaths = deaths[4] + deaths[10] + deaths[16],
    african_american_deaths = deaths[2] + deaths[8] + deaths[14],
    asian_deaths = deaths[5] + deaths[11] + deaths[17],
    other_race_deaths = deaths[6] + deaths[12] + deaths[18]
  ))
}

mississippi = extract_mississippi_data()
mississippi
```

# Florida

```{r}
extract_florida_data = function(pdf_url) {
  # Get pdf from: https://www.floridadisaster.org/covid19/covid-19-data-reports/
  
  data = pdf_text(pdf_url)
  
  demographic_data = data %>% .[3] %>% 
    str_split(., "\n") %>% .[[1]] %>% 
    str_squish()
  
  
  
  cases = demographic_data %>% .[16] %>% 
    str_split(., " ", simplify = TRUE) %>% .[1, 2] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  deaths = demographic_data %>% .[16] %>% 
    str_split(., " ", simplify = TRUE) %>% .[1, 4] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  males = demographic_data %>% .[5] %>% 
    str_split(., " ", simplify = TRUE) %>%  .[1, 10] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  between_0_and_4 = demographic_data %>% .[5] %>% 
    str_split(., " ", simplify = TRUE) %>%  .[1, 3] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  between_5_and_14 = demographic_data %>% .[6] %>% 
    str_split(., " ", simplify = TRUE) %>%  .[1, 3] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  between_15_and_24 = demographic_data %>% .[7] %>% 
    str_split(., " ", simplify = TRUE) %>%  .[1, 3] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  between_25_and_34 = demographic_data %>% .[8] %>% 
    str_split(., " ", simplify = TRUE) %>%  .[1, 3] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  between_35_and_44 = demographic_data %>% .[9] %>% 
    str_split(., " ", simplify = TRUE) %>%  .[1, 3] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  between_45_and_54 = demographic_data %>% .[10] %>% 
    str_split(., " ", simplify = TRUE) %>%  .[1, 3] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  between_55_and_64 = demographic_data %>% .[11] %>% 
    str_split(., " ", simplify = TRUE) %>%  .[1, 3] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  between_65_and_74 = demographic_data %>% .[12] %>% 
    str_split(., " ", simplify = TRUE) %>%  .[1, 3] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  between_75_and_84 = demographic_data %>% .[13] %>% 
    str_split(., " ", simplify = TRUE) %>%  .[1, 3] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  older_than_85 = demographic_data %>% .[14] %>% 
    str_split(., " ", simplify = TRUE) %>%  .[1, 3] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  unknown_age = demographic_data %>% .[15] %>% 
    str_split(., " ", simplify = TRUE) %>%  .[1, 2] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  white = demographic_data %>% .[23] %>% 
    str_split(., " ", simplify = TRUE) %>%  .[1, 2] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  black = demographic_data %>% .[27] %>% 
    str_split(., " ", simplify = TRUE) %>%  .[1, 2] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  other_race = demographic_data %>% .[31] %>% 
    str_split(., " ", simplify = TRUE) %>%  .[1, 2] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  unknown_race = demographic_data %>% .[35] %>% 
    str_split(., " ", simplify = TRUE) %>%  .[1, 3] %>% 
    str_replace(., ",", "") %>% as.numeric()
  
  return(list(
    cases = cases,
    deaths = deaths,
    males = males,
    between_0_and_4 = between_0_and_4,
    between_5_and_14 = between_5_and_14,
    between_15_and_24 = between_15_and_24,
    between_25_and_34 = between_25_and_34,
    between_35_and_44 = between_35_and_44,
    between_45_and_54 = between_45_and_54,
    between_55_and_64 = between_55_and_64,
    between_65_and_74 = between_65_and_74,
    between_75_and_84 = between_75_and_84,
    older_than_85 = older_than_85,
    unknown_age = unknown_age,
    white = white,
    black = black,
    other_race = other_race,
    unknown_race = unknown_race
  ))
  
}

florida = extract_florida_data("https://www.floridadisaster.org/globalassets/covid19/dailies/covid-19-data---daily-report-2020-05-07-0956.pdf")
  
```

```{r}
florida %>%  str_squish
```

```{r}
a = list(
  x = c(one = 1, two = 2, three = 3),
  y = c(one = 4, two = 5, three = 6),
  z = c(one = 7, two = 8, three = 9)
)

as_tibble(a)
```

```{r}
b = c(one = 1, two = 2, three = 3)
b["one"]
```



```{r}
d = c(1,2,3)
names(d) = c("yes", "no", "what")
d
```

