---
title: "Courtney Manual Scraping Workflow"
---

```{r}
# Step 1: Load in my R source files
library(tidyverse)
library(pdftools)
library(rvest)
library(lubridate)
library(readxl)
source("./source/states.R")
source("./source/states_constants.R")
```

```{r}
# Step 2: Do the data entry 
hawaii = get_hawaii() # Courtney
# manually add filipino, chinese, japanese and other asian
# manually add native hawaiian and pacific islander


# idaho = get_idaho() # Courtney

arizona = get_arizona()

```

```{r}
# Step 3: combine the two states together with bind_rows
# Name your variable like manual_data_yearmonthday_initials
# ie: manual_data_20200519_cbp = bind_rows(arizona, kansas, iowa)

manual_data_20200609_cej = bind_rows(hawaii, arizona)
```

```{r}
# Step 4: save your data as an Rda with a similar name
# ie: save(manual_data_20200519_cbp, file = "manual_data_20200519_cbp.rda")

save(manual_data_20200609_cej, file = "manual_data_20200609_cej.rda")

# Then place into the Sharepoint! 
# As Aijin suggested, try doing this at least one day a week, like Friday
# Thanks everyone for helping out
```

